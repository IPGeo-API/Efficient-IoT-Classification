{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 1D IoT Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Concatenate\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform\n",
    "from keras.utils import multi_gpu_model\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open and Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data():\n",
    "    import tensorflow as tf\n",
    "    hdf5_path = 'Data/dataset.hdf5'\n",
    "    subtract_mean = True\n",
    "\n",
    "    hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "\n",
    "    if subtract_mean:\n",
    "        mm = hdf5_file[\"train_mean\"][...,0]\n",
    "        mm = mm[np.newaxis, ...]\n",
    "\n",
    "    data_num = hdf5_file[\"train_flow\"].shape[0]\n",
    "    \n",
    "    #batch_size = 512\n",
    "    num_classes = 2\n",
    "    epochs = 30\n",
    "\n",
    "    flow_rows, flow_cols = 298, 17\n",
    "\n",
    "    x_train = hdf5_file[\"train_flow\"][...,0]\n",
    "    \n",
    "    if subtract_mean:\n",
    "        x_train -= mm\n",
    "\n",
    "    y_train = hdf5_file[\"train_labels\"][:,...]\n",
    "    hdf5_file.close()\n",
    "\n",
    "    hdf5_path = 'Data/dataset-IoT.hdf5'\n",
    "    hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "\n",
    "\n",
    "    x_test = hdf5_file[\"IoT_flow\"][...,0]\n",
    "    if subtract_mean:\n",
    "        x_test -= mm\n",
    "\n",
    "    y_test = hdf5_file[\"labels\"][:,...]\n",
    "\n",
    "    hdf5_file.close()\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "    d_class_weights = dict(enumerate(class_weights))\n",
    "    #print(d_class_weights)\n",
    "\n",
    "    input_shape = (x_train.shape[1], x_train.shape[2])\n",
    "    \n",
    "    #print('x_train shape:', x_train.shape)\n",
    "    #print(x_train.shape[0], 'train samples')\n",
    "    #print(x_test.shape[0], 'test samples')\n",
    "    \n",
    "    y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "    y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buld the CNN 1D Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(x_train, y_train, x_test, y_test):\n",
    "    num_classes = 2\n",
    "    high = {{choice([40,50,60,70,80])}}\n",
    "    \n",
    "    filter_lenghts =  [int(i) for i in np.arange(2,high,2)]\n",
    "    print(filter_lenghts)\n",
    "    convs = []\n",
    "    maxlen = 298\n",
    "    batch_size = {{choice([256,512,1024])}}\n",
    "    epochs = 30\n",
    "    numFilters={{choice([32,64,128])}}\n",
    "    activations={{choice(['relu', 'sigmoid', 'tanh'])}}\n",
    "    dropoutVal = {{uniform(0.1, 0.3)}}\n",
    "    lr = {{uniform(0.0009, 0.00225)}}\n",
    "    adam = keras.optimizers.Adam(lr=lr)\n",
    "    rmsprop = keras.optimizers.RMSprop(lr=lr)\n",
    "    sgd = keras.optimizers.SGD(lr=lr)\n",
    "\n",
    "    choiceval = {{choice(['adam', 'sgd', 'rmsprop'])}}\n",
    "    if choiceval == 'adam':\n",
    "        optim = adam\n",
    "    elif choiceval == 'rmsprop':\n",
    "        optim = rmsprop\n",
    "    else:\n",
    "        optim = sgd\n",
    "    input_flow = Input(shape=input_shape)\n",
    "\n",
    "    convs= {}\n",
    "    mpoolings = {}\n",
    "    flattens = {}\n",
    "    convs_out = []\n",
    "    for i in filter_lenghts:\n",
    "        convs[str(i)+'_convolution']=Conv1D(filters=numFilters,kernel_size=i,padding=\"valid\",activation=activations,strides=1)(input_flow)\n",
    "\n",
    "        mpoolings[str(i)+'_maxpooling'] = MaxPooling1D(pool_size= maxlen - i + 1)(convs[str(i)+'_convolution'])\n",
    "        flattens[str(i)+'_flattenout'] = Flatten()(mpoolings[str(i)+'_maxpooling'])\n",
    "        convs_out.append(flattens[str(i)+'_flattenout'])\n",
    "    out = Concatenate()(convs_out)\n",
    "    dropout = Dropout(dropoutVal)(out)\n",
    "    dense = Dense(64, activation='relu')(dropout)\n",
    "    dense2 = Dense(32, activation='relu')(dense)\n",
    "    dropout2 = Dropout(dropoutVal)(dense2)\n",
    "    end = Dense(num_classes, activation='softmax')(dropout2)\n",
    "\n",
    "    model = Model(inputs=input_flow, outputs=end) \n",
    "    model.summary()\n",
    "    try:\n",
    "        model = multi_gpu_model(model, gpus = 4)\n",
    "    except:\n",
    "        pass\n",
    "    model.compile(loss='binary_crossentropy',optimizer=optim,metrics=['accuracy'])\n",
    "    model.fit(x_train, y_train,batch_size=batchSize, epochs=30, verbose=0, validation_split=0.2, class_weight=class_weights, shuffle=True)\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    loss = score[0]\n",
    "    return {'loss': loss, 'status': STATUS_OK, 'model': model} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = data()\n",
    "best_run, best_model = optim.minimize(model=create_model, data=data, algo=tpe.suggest, max_evals=100, trials=Trials(), eval_space=True, notebook_name='MW-1D-CNN')\n",
    "\n",
    "print(\"Evalutation of best performing model:\")\n",
    "print(best_model.evaluate(x_test, y_test))\n",
    "print(\"Best performing model chosen hyper-parameters:\")\n",
    "print(best_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Analysis\n",
    "#### Classification Report\n",
    "#### Confusion Matrix\n",
    "#### Area Under Reciever Operating Characteristic Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = best_model.predict(x_test)\n",
    "yy_test = [np.argmax(i) for i in y_test]\n",
    "\n",
    "yy_pred = [np.argmax(i) for i in y_pred]\n",
    "\n",
    "print(classification_report(yy_test, yy_pred))     \n",
    "  \n",
    "new = np.vstack([yy_test,yy_pred])\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "print(confusion_matrix(yy_test, yy_pred))\n",
    "\n",
    "\n",
    "\n",
    "y_pred_keras = best_model.predict(x_test).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(yy_test, y_pred[:,0],pos_label=0)\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "print(auc_keras)\n",
    "\n",
    "f1 = plt.figure()\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='AUC = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "f1.savefig(\"ROC-curve-cnn1D-MW.pdf\", bbox_inches='tight')\n",
    "\n",
    "f2 = plt.figure()\n",
    "plt.xlim(0, 0.4)\n",
    "plt.ylim(0.6, 1)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.plot(fpr_keras, tpr_keras, label='AUC = {:.3f}'.format(auc_keras))\n",
    "plt.xlabel('False positive rate')\n",
    "plt.ylabel('True positive rate')\n",
    "plt.title('ROC curve (zoomed in at top left)')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "f2.savefig(\"ROC-curve-zoomed-cnn1D-MW.pdf\", bbox_inches='tight')\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(yy_test,  y_pred[:,0],pos_label=0)\n",
    "# calculate F1 score\n",
    "#f1 = f1_score(yy_test, y_pred)\n",
    "# calculate precision-recall AUC\n",
    "auc_score = auc(recall, precision)\n",
    "print(auc_score)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(yy_test, y_pred[:,1])\n",
    "print(ap)\n",
    "#print('auc=%.3f ap=%.3f' % (auc, ap))\n",
    "# plot no skill\n",
    "f3 = plt.figure()\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the precision-recall curve for the model\n",
    "plt.plot( recall, precision,marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision Recall Curve')\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n",
    "f3.savefig(\"precisionrecall-cnn1D-MW.pdf\", bbox_inches='tight')\n",
    "num_positive = float(np.count_nonzero(yy_test))\n",
    "num_negative = float(len(yy_test) - num_positive)\n",
    "pos_weight = num_negative / num_positive\n",
    "weights = np.ones_like(yy_test)\n",
    "weights[yy_test != np.float64(0)] = pos_weight\n",
    "\n",
    "\n",
    "precision_weighted, recall_weighted, thresholds_weighted = precision_recall_curve(yy_test,  y_pred[:,0],pos_label=0,sample_weight=weights)\n",
    "#calculate F1 score\n",
    "#f1 = f1_score(yy_test, y_pred)\n",
    "# calculate precision-recall AUC\n",
    "auc_score = auc(recall_weighted, precision_weighted)\n",
    "print(auc_score)\n",
    "# calculate average precision score\n",
    "ap = average_precision_score(yy_test, y_pred[:,1])\n",
    "print(ap)\n",
    "#print('auc=%.3f ap=%.3f' % (auc, ap))\n",
    "# plot no skill\n",
    "f4 = plt.figure()\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "# plot the weighted precision-recall curve for the model\n",
    "plt.plot( recall_weighted, precision_weighted,marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Weighted Precision Recall Curve')\n",
    "# show the plot\n",
    "plt.show()\n",
    "f4.savefig(\"weightedprecisionrecall-cnn1D-MW.pdf\", bbox_inches='tight')\n",
    "\n",
    "best_model.save('cnn1D-MW.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model Analysis Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'False Positive Rate': fpr_keras, 'True Positive Rate': tpr_keras , 'Thresholds': thresholds_keras}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_CNN1D = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_CNN1D.to_csv(path_or_buf ='rocCNN1D-50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(yy_test, yy_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf1D=pd.DataFrame(data=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf1D.to_csv(path_or_buf='ConfusionCNN1D-50.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"precision\" : precision, \"recall\" :recall}).to_csv(\"precisionrecall-1dseq.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"precision\" : precision_weighted, \"recall\" :recall_weighted}).to_csv(\"weightedprecisionrecall-1dseq.csv\", index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
