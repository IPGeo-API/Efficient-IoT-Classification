{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Concatenate\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "\n",
    "import gc\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path = 'Data/dataset.hdf5'\n",
    "subtract_mean = True\n",
    "\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "\n",
    "if subtract_mean:\n",
    "    mm = hdf5_file[\"train_mean\"][...,0]\n",
    "    mm = mm[np.newaxis, ...]\n",
    "\n",
    "data_num = hdf5_file[\"train_flow\"].shape[0]\n",
    "    \n",
    "num_classes = 2\n",
    "epochs = 30\n",
    "\n",
    "flow_rows, flow_cols = 298, 17\n",
    "\n",
    "x_train = hdf5_file[\"train_flow\"][...,0]\n",
    "if subtract_mean:\n",
    "    x_train -= mm\n",
    "\n",
    "y_train = hdf5_file[\"train_labels\"][:,...]\n",
    "hdf5_file.close()\n",
    "hdf5_path = 'Data/dataset-IoT.hdf5'\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "\n",
    "\n",
    "x_test = hdf5_file[\"IoT_flow\"][...,0]\n",
    "if subtract_mean:\n",
    "    x_test -= mm\n",
    "\n",
    "y_test = hdf5_file[\"labels\"][:,...]\n",
    "\n",
    "hdf5_file.close()\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "input_shape = (x_train.shape[1], x_train.shape[2])\n",
    "    \n",
    "    \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "accuracy: 88.79930%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.88755   0.99045   0.93618     34974\n",
      "           1    0.89356   0.38982   0.54283      7193\n",
      "\n",
      "    accuracy                        0.88799     42167\n",
      "   macro avg    0.89055   0.69014   0.73951     42167\n",
      "weighted avg    0.88857   0.88799   0.86908     42167\n",
      "\n",
      "accuracy: 88.63567%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.88450   0.99259   0.93544     34974\n",
      "           1    0.91127   0.36980   0.52611      7193\n",
      "\n",
      "    accuracy                        0.88636     42167\n",
      "   macro avg    0.89789   0.68120   0.73077     42167\n",
      "weighted avg    0.88907   0.88636   0.86561     42167\n",
      "\n",
      "accuracy: 89.34001%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89426   0.98833   0.93895     34974\n",
      "           1    0.88389   0.43181   0.58018      7193\n",
      "\n",
      "    accuracy                        0.89340     42167\n",
      "   macro avg    0.88908   0.71007   0.75957     42167\n",
      "weighted avg    0.89250   0.89340   0.87775     42167\n",
      "\n",
      "accuracy: 89.32577%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89630   0.98530   0.93870     34974\n",
      "           1    0.86183   0.44571   0.58756      7193\n",
      "\n",
      "    accuracy                        0.89326     42167\n",
      "   macro avg    0.87906   0.71551   0.76313     42167\n",
      "weighted avg    0.89042   0.89326   0.87880     42167\n",
      "\n",
      "accuracy: 89.72419%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.90097   0.98430   0.94079     34974\n",
      "           1    0.86129   0.47393   0.61142      7193\n",
      "\n",
      "    accuracy                        0.89724     42167\n",
      "   macro avg    0.88113   0.72912   0.77611     42167\n",
      "weighted avg    0.89420   0.89724   0.88461     42167\n",
      "\n",
      "accuracy: 88.92025%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.88921   0.98974   0.93678     34974\n",
      "           1    0.88916   0.40039   0.55215      7193\n",
      "\n",
      "    accuracy                        0.88920     42167\n",
      "   macro avg    0.88918   0.69506   0.74446     42167\n",
      "weighted avg    0.88920   0.88920   0.87117     42167\n",
      "\n",
      "accuracy: 89.36846%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89526   0.98733   0.93904     34974\n",
      "           1    0.87681   0.43834   0.58448      7193\n",
      "\n",
      "    accuracy                        0.89368     42167\n",
      "   macro avg    0.88603   0.71284   0.76176     42167\n",
      "weighted avg    0.89211   0.89368   0.87856     42167\n",
      "\n",
      "accuracy: 89.07914%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.88974   0.99116   0.93772     34974\n",
      "           1    0.90362   0.40275   0.55717      7193\n",
      "\n",
      "    accuracy                        0.89079     42167\n",
      "   macro avg    0.89668   0.69696   0.74744     42167\n",
      "weighted avg    0.89210   0.89079   0.87280     42167\n",
      "\n",
      "accuracy: 89.07676%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89122   0.98902   0.93758     34974\n",
      "           1    0.88554   0.41304   0.56333      7193\n",
      "\n",
      "    accuracy                        0.89077     42167\n",
      "   macro avg    0.88838   0.70103   0.75045     42167\n",
      "weighted avg    0.89025   0.89077   0.87374     42167\n",
      "\n",
      "accuracy: 89.49652%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89438   0.99031   0.93990     34974\n",
      "           1    0.90151   0.43139   0.58354      7193\n",
      "\n",
      "    accuracy                        0.89497     42167\n",
      "   macro avg    0.89795   0.71085   0.76172     42167\n",
      "weighted avg    0.89560   0.89497   0.87912     42167\n",
      "\n",
      "accuracy: 89.29969%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89353   0.98882   0.93876     34974\n",
      "           1    0.88709   0.42708   0.57658      7193\n",
      "\n",
      "    accuracy                        0.89300     42167\n",
      "   macro avg    0.89031   0.70795   0.75767     42167\n",
      "weighted avg    0.89243   0.89300   0.87698     42167\n",
      "\n",
      "accuracy: 89.21431%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89160   0.99036   0.93839     34974\n",
      "           1    0.89846   0.41457   0.56735      7193\n",
      "\n",
      "    accuracy                        0.89214     42167\n",
      "   macro avg    0.89503   0.70247   0.75287     42167\n",
      "weighted avg    0.89277   0.89214   0.87510     42167\n",
      "\n",
      "accuracy: 89.47281%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89474   0.98948   0.93973     34974\n",
      "           1    0.89456   0.43403   0.58448      7193\n",
      "\n",
      "    accuracy                        0.89473     42167\n",
      "   macro avg    0.89465   0.71176   0.76210     42167\n",
      "weighted avg    0.89471   0.89473   0.87913     42167\n",
      "\n",
      "accuracy: 90.21984%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.90435   0.98642   0.94360     34974\n",
      "           1    0.88181   0.49270   0.63218      7193\n",
      "\n",
      "    accuracy                        0.90220     42167\n",
      "   macro avg    0.89308   0.73956   0.78789     42167\n",
      "weighted avg    0.90050   0.90220   0.89048     42167\n",
      "\n",
      "accuracy: 89.55344%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89533   0.98976   0.94018     34974\n",
      "           1    0.89783   0.43737   0.58820      7193\n",
      "\n",
      "    accuracy                        0.89553     42167\n",
      "   macro avg    0.89658   0.71357   0.76419     42167\n",
      "weighted avg    0.89575   0.89553   0.88014     42167\n",
      "\n",
      "accuracy: 88.88941%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89037   0.98765   0.93649     34974\n",
      "           1    0.87189   0.40873   0.55655      7193\n",
      "\n",
      "    accuracy                        0.88889     42167\n",
      "   macro avg    0.88113   0.69819   0.74652     42167\n",
      "weighted avg    0.88722   0.88889   0.87168     42167\n",
      "\n",
      "accuracy: 89.77399%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89677   0.99076   0.94142     34974\n",
      "           1    0.90842   0.44543   0.59776      7193\n",
      "\n",
      "    accuracy                        0.89774     42167\n",
      "   macro avg    0.90259   0.71810   0.76959     42167\n",
      "weighted avg    0.89875   0.89774   0.88280     42167\n",
      "\n",
      "accuracy: 89.13605%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89149   0.98945   0.93792     34974\n",
      "           1    0.88985   0.41443   0.56549      7193\n",
      "\n",
      "    accuracy                        0.89136     42167\n",
      "   macro avg    0.89067   0.70194   0.75171     42167\n",
      "weighted avg    0.89121   0.89136   0.87439     42167\n",
      "\n",
      "accuracy: 89.42775%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89549   0.98782   0.93939     34974\n",
      "           1    0.88124   0.43946   0.58646      7193\n",
      "\n",
      "    accuracy                        0.89428     42167\n",
      "   macro avg    0.88836   0.71364   0.76292     42167\n",
      "weighted avg    0.89306   0.89428   0.87919     42167\n",
      "\n",
      "accuracy: 89.19771%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89268   0.98862   0.93820     34974\n",
      "           1    0.88410   0.42208   0.57137      7193\n",
      "\n",
      "    accuracy                        0.89198     42167\n",
      "   macro avg    0.88839   0.70535   0.75479     42167\n",
      "weighted avg    0.89121   0.89198   0.87563     42167\n",
      "\n",
      "accuracy: 89.07440%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89168   0.98833   0.93752     34974\n",
      "           1    0.88007   0.41624   0.56517      7193\n",
      "\n",
      "    accuracy                        0.89074     42167\n",
      "   macro avg    0.88588   0.70229   0.75135     42167\n",
      "weighted avg    0.88970   0.89074   0.87401     42167\n",
      "\n",
      "accuracy: 89.11945%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89238   0.98796   0.93774     34974\n",
      "           1    0.87786   0.42069   0.56880      7193\n",
      "\n",
      "    accuracy                        0.89119     42167\n",
      "   macro avg    0.88512   0.70432   0.75327     42167\n",
      "weighted avg    0.88990   0.89119   0.87481     42167\n",
      "\n",
      "accuracy: 89.06254%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89042   0.98996   0.93756     34974\n",
      "           1    0.89309   0.40762   0.55976      7193\n",
      "\n",
      "    accuracy                        0.89063     42167\n",
      "   macro avg    0.89175   0.69879   0.74866     42167\n",
      "weighted avg    0.89087   0.89063   0.87311     42167\n",
      "\n",
      "accuracy: 88.62143%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.88622   0.98991   0.93520     34974\n",
      "           1    0.88617   0.38204   0.53390      7193\n",
      "\n",
      "    accuracy                        0.88621     42167\n",
      "   macro avg    0.88619   0.68597   0.73455     42167\n",
      "weighted avg    0.88621   0.88621   0.86674     42167\n",
      "\n",
      "accuracy: 89.20246%\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0    0.89954   0.99157   0.94331     34974\n",
      "           1    0.91840   0.46156   0.61436      7193\n",
      "\n",
      "    accuracy                        0.90115     42167\n",
      "   macro avg    0.90897   0.72656   0.77884     42167\n",
      "weighted avg    0.90276   0.90115   0.88720     42167\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a46eebea29ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m     \u001b[1;31m#F1Scores.append(f1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m     \u001b[0map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maverage_precision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myy_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m     \u001b[0mPrecisionScores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36maverage_precision_score\u001b[1;34m(y_true, y_score, average, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    213\u001b[0m                                 pos_label=pos_label)\n\u001b[0;32m    214\u001b[0m     return _average_binary_score(average_precision, y_true, y_score,\n\u001b[1;32m--> 215\u001b[1;33m                                  average, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    216\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\sklearn\\metrics\\_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 77\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_uninterpolated_average_precision\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    194\u001b[0m             y_true, y_score, pos_label=1, sample_weight=None):\n\u001b[0;32m    195\u001b[0m         precision, recall, _ = precision_recall_curve(\n\u001b[1;32m--> 196\u001b[1;33m             y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    197\u001b[0m         \u001b[1;31m# Return the step function integral\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[1;31m# The following works because the last entry of precision is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[1;34m(y_true, probas_pred, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    671\u001b[0m     fps, tps, thresholds = _binary_clf_curve(y_true, probas_pred,\n\u001b[0;32m    672\u001b[0m                                              \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 673\u001b[1;33m                                              sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    674\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    675\u001b[0m     \u001b[0mprecision\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtps\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtps\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\sklearn\\metrics\\_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    540\u001b[0m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    541\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m     \u001b[0massert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36massert_all_finite\u001b[1;34m(X, allow_nan)\u001b[0m\n\u001b[0;32m     75\u001b[0m     \u001b[0mallow_nan\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \"\"\"\n\u001b[1;32m---> 77\u001b[1;33m     \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "AccScores = []\n",
    "AucScores = []\n",
    "#F1Scores = []\n",
    "#PrecisionScores = []\n",
    "for i in range (1,50):\n",
    "    size = 64\n",
    "    nb_filters = 32\n",
    "    num_classes = 2\n",
    "    epochs=30\n",
    "    activations= \"tanh\"\n",
    "    maxlen=298\n",
    "    dropout = 0.24295335733172563\n",
    "    batch_size = 512\n",
    "    pool_size = 3\n",
    "    lr = 0.0012168203727788032\n",
    "    adam = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "    optim = adam\n",
    "\n",
    "    layers = 3\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=nb_filters,kernel_size=size,input_shape=(input_shape),padding=\"valid\",activation=activations,strides=1))\n",
    "    for i in range(layers-1):\n",
    "        model.add(Conv1D(filters=nb_filters,kernel_size=size,padding=\"valid\",activation=activations,strides=1))\n",
    "        \n",
    "    model.add(MaxPooling1D(pool_size= pool_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    #model.summary()\n",
    "    try:\n",
    "        model = multi_gpu_model(model, gpus = 4)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    model.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, verbose=0, class_weight=class_weights, shuffle=True)\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print(\"%s: %.5f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    AccScores.append(scores[1] * 100)\n",
    "    y_pred = model.predict(x_test)\n",
    "    yy_test = [np.argmax(i) for i in y_test]\n",
    "\n",
    "    yy_pred = [np.argmax(i) for i in y_pred]\n",
    "  \n",
    "    new = np.vstack([yy_test,yy_pred])\n",
    "    print(classification_report(yy_test, yy_pred, digits = 5 ))\n",
    "    #f1 = f1_score(yy_test, y_pred)\n",
    "    #F1Scores.append(f1)\n",
    "    \n",
    "    #ap = average_precision_score(yy_test, y_pred[:,1])\n",
    "    #PrecisionScores.append(ap)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    fpr_keras, tpr_keras, thresholds_keras = roc_curve(yy_test, y_pred[:,0],pos_label=0)\n",
    "    auc_keras = auc(fpr_keras, tpr_keras)\n",
    "    AucScores.append(auc_keras)\n",
    "    del model\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "print(\"%.5f%% (+/- %.5f%%)\" % (np.mean(AccScores), np.std(AccScores)))\n",
    "print(\"%.5f%% (+/- %.5f%%)\" % (np.mean(AucScores), np.std(AucScores)))\n",
    "#print(\"%.5f%% (+/- %.5f%%)\" % (np.mean(F1Scores), np.std(F1Scores)))\n",
    "#print(\"%.5f%% (+/- %.5f%%)\" % (np.mean(PrecisionScores), np.std(PrecisionScores)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
