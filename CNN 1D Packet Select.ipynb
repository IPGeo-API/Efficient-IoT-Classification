{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Input, Concatenate\n",
    "from keras.layers import Conv1D, MaxPooling1D, AveragePooling1D\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "from keras.utils import multi_gpu_model\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import copy\n",
    "import tensorflow as tf\n",
    "\n",
    "import gc\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdf5_path = 'Data/dataset.hdf5'\n",
    "subtract_mean = True\n",
    "\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "\n",
    "if subtract_mean:\n",
    "    mm = hdf5_file[\"train_mean\"][...,0]\n",
    "    mm = mm[np.newaxis, ...]\n",
    "\n",
    "data_num = hdf5_file[\"train_flow\"].shape[0]\n",
    "    \n",
    "num_classes = 2\n",
    "epochs = 30\n",
    "\n",
    "flow_rows, flow_cols = 298, 17\n",
    "\n",
    "x_train = hdf5_file[\"train_flow\"][...,0]\n",
    "if subtract_mean:\n",
    "    x_train -= mm\n",
    "\n",
    "y_train = hdf5_file[\"train_labels\"][:,...]\n",
    "hdf5_file.close()\n",
    "hdf5_path = 'Data/dataset-IoT.hdf5'\n",
    "hdf5_file = h5py.File(hdf5_path, \"r\")\n",
    "\n",
    "\n",
    "x_test = hdf5_file[\"IoT_flow\"][...,0]\n",
    "if subtract_mean:\n",
    "    x_test -= mm\n",
    "\n",
    "y_test = hdf5_file[\"labels\"][:,...]\n",
    "\n",
    "hdf5_file.close()\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "d_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "#define number of packets used to train for each device\n",
    "packets = 200\n",
    "x_train = x_train[:,:packets,:]\n",
    "x_test = x_test[:,:packets,:]\n",
    "\n",
    "input_shape = (x_train.shape[1], x_train.shape[2])\n",
    "    \n",
    "    \n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From c:\\users\\mrathbun2018\\.conda\\envs\\mattwork\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "accuracy: 89.10522%\n",
      "loss: 0.25438%\n",
      "Fit and Evaluate Time: 73.58207058906555\n",
      "accuracy: 89.03645%\n",
      "loss: 0.25467%\n",
      "Fit and Evaluate Time: 67.9497230052948\n",
      "accuracy: 89.33526%\n",
      "loss: 0.25360%\n",
      "Fit and Evaluate Time: 66.09202003479004\n",
      "accuracy: 88.51709%\n",
      "loss: 0.26865%\n",
      "Fit and Evaluate Time: 66.40930938720703\n",
      "accuracy: 89.10285%\n",
      "loss: 0.26269%\n",
      "Fit and Evaluate Time: 66.01029968261719\n",
      "accuracy: 88.60246%\n",
      "loss: 0.26004%\n",
      "Fit and Evaluate Time: 66.26499557495117\n",
      "accuracy: 89.28072%\n",
      "loss: 0.25897%\n",
      "Fit and Evaluate Time: 65.97678899765015\n",
      "accuracy: 88.77084%\n",
      "loss: 0.25462%\n",
      "Fit and Evaluate Time: 65.20565915107727\n",
      "accuracy: 89.34001%\n",
      "loss: 0.25363%\n",
      "Fit and Evaluate Time: 65.61148595809937\n",
      "accuracy: 88.00958%\n",
      "loss: 0.27674%\n",
      "Fit and Evaluate Time: 66.53992629051208\n",
      "accuracy: 89.23091%\n",
      "loss: 0.26955%\n",
      "Fit and Evaluate Time: 65.16773509979248\n",
      "accuracy: 89.05542%\n",
      "loss: 0.25409%\n",
      "Fit and Evaluate Time: 65.92559599876404\n",
      "accuracy: 88.89890%\n",
      "loss: 0.25828%\n",
      "Fit and Evaluate Time: 67.15752220153809\n",
      "accuracy: 88.96530%\n",
      "loss: 0.25738%\n",
      "Fit and Evaluate Time: 65.67529726028442\n",
      "accuracy: 88.92262%\n",
      "loss: 0.26277%\n",
      "Fit and Evaluate Time: 66.60524153709412\n",
      "accuracy: 88.27519%\n",
      "loss: 0.27176%\n",
      "Fit and Evaluate Time: 66.53224110603333\n",
      "accuracy: 89.04356%\n",
      "loss: 0.24873%\n",
      "Fit and Evaluate Time: 66.14062714576721\n",
      "accuracy: 89.57953%\n",
      "loss: 0.25570%\n",
      "Fit and Evaluate Time: 65.496098279953\n",
      "accuracy: 89.30444%\n",
      "loss: 0.26295%\n",
      "Fit and Evaluate Time: 66.73258566856384\n",
      "accuracy: 89.37558%\n",
      "loss: 0.26155%\n",
      "Fit and Evaluate Time: 66.54114866256714\n",
      "accuracy: 89.11945%\n",
      "loss: 0.25739%\n",
      "Fit and Evaluate Time: 66.388028383255\n",
      "accuracy: 88.41748%\n",
      "loss: 0.26006%\n",
      "Fit and Evaluate Time: 65.91399812698364\n",
      "accuracy: 89.10760%\n",
      "loss: 0.25518%\n",
      "Fit and Evaluate Time: 66.5015778541565\n",
      "accuracy: 89.32104%\n",
      "loss: 0.25594%\n",
      "Fit and Evaluate Time: 65.91160345077515\n",
      "accuracy: 89.41827%\n",
      "loss: 0.25780%\n",
      "Fit and Evaluate Time: 65.80597567558289\n",
      "accuracy: 89.44435%\n",
      "loss: 0.24904%\n",
      "Fit and Evaluate Time: 66.72379064559937\n",
      "accuracy: 88.50523%\n",
      "loss: 0.26518%\n",
      "Fit and Evaluate Time: 65.20480751991272\n",
      "accuracy: 89.34475%\n",
      "loss: 0.25775%\n",
      "Fit and Evaluate Time: 66.84970307350159\n",
      "accuracy: 88.87756%\n",
      "loss: 0.25866%\n",
      "Fit and Evaluate Time: 65.67833209037781\n",
      "accuracy: 89.85463%\n",
      "loss: 0.24556%\n",
      "Fit and Evaluate Time: 66.23423457145691\n",
      "accuracy: 89.26412%\n",
      "loss: 0.25079%\n",
      "Fit and Evaluate Time: 65.36672830581665\n",
      "accuracy: 89.01036%\n",
      "loss: 0.26172%\n",
      "Fit and Evaluate Time: 65.6241614818573\n",
      "accuracy: 88.26808%\n",
      "loss: 0.25873%\n",
      "Fit and Evaluate Time: 66.21689987182617\n",
      "accuracy: 88.24673%\n",
      "loss: 0.26952%\n",
      "Fit and Evaluate Time: 66.76148271560669\n",
      "accuracy: 88.54317%\n",
      "loss: 0.26201%\n",
      "Fit and Evaluate Time: 65.87491464614868\n",
      "accuracy: 88.93922%\n",
      "loss: 0.25170%\n",
      "Fit and Evaluate Time: 66.12395215034485\n",
      "accuracy: 88.43883%\n",
      "loss: 0.25689%\n",
      "Fit and Evaluate Time: 65.21816635131836\n",
      "accuracy: 88.43645%\n",
      "loss: 0.26715%\n",
      "Fit and Evaluate Time: 66.76885986328125\n",
      "accuracy: 89.24752%\n",
      "loss: 0.25163%\n",
      "Fit and Evaluate Time: 65.84142899513245\n",
      "accuracy: 89.45621%\n",
      "loss: 0.25161%\n",
      "Fit and Evaluate Time: 66.20994973182678\n",
      "accuracy: 88.38665%\n",
      "loss: 0.26789%\n",
      "Fit and Evaluate Time: 65.91570496559143\n",
      "accuracy: 88.55740%\n",
      "loss: 0.25702%\n",
      "Fit and Evaluate Time: 65.62564492225647\n",
      "accuracy: 88.40088%\n",
      "loss: 0.25929%\n",
      "Fit and Evaluate Time: 65.70773124694824\n",
      "accuracy: 89.09337%\n",
      "loss: 0.25923%\n",
      "Fit and Evaluate Time: 66.72771191596985\n",
      "accuracy: 88.52420%\n",
      "loss: 0.26365%\n",
      "Fit and Evaluate Time: 65.6626398563385\n",
      "accuracy: 89.22617%\n",
      "loss: 0.25290%\n",
      "Fit and Evaluate Time: 65.69525027275085\n",
      "accuracy: 88.04516%\n",
      "loss: 0.26422%\n",
      "Fit and Evaluate Time: 65.56711387634277\n",
      "accuracy: 88.98427%\n",
      "loss: 0.25475%\n",
      "Fit and Evaluate Time: 66.36722707748413\n",
      "accuracy: 88.38903%\n",
      "loss: 0.25856%\n",
      "Fit and Evaluate Time: 65.67475295066833\n",
      "88.91061% (+/- 0.43503%)\n",
      "0.25883% (+/- 0.00632%)\n",
      "66.24038% (+/- 1.19553%)\n",
      "Time to do everything: 3275.232642889023\n"
     ]
    }
   ],
   "source": [
    "AccScores = []\n",
    "Times = []\n",
    "LossScores = []\n",
    "#AucScores = []\n",
    "#F1Scores = []\n",
    "#PrecisionScores = []\n",
    "t2 = time.time()\n",
    "\n",
    "for i in range (1,50):\n",
    "    size = 64\n",
    "    nb_filters = 32\n",
    "    num_classes = 2\n",
    "    epochs=30\n",
    "    activations= \"tanh\"\n",
    "    maxlen=packets\n",
    "    dropout = 0.24295335733172563\n",
    "    batch_size = 512\n",
    "    pool_size = 3\n",
    "    lr = 0.0012168203727788032\n",
    "    adam = keras.optimizers.Adam(lr=lr)\n",
    "\n",
    "    optim = adam\n",
    "\n",
    "    layers = 3\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=nb_filters,kernel_size=size,input_shape=(input_shape),padding=\"valid\",activation=activations,strides=1))\n",
    "    for i in range(layers-1):\n",
    "        model.add(Conv1D(filters=nb_filters,kernel_size=size,padding=\"valid\",activation=activations,strides=1))\n",
    "        \n",
    "    model.add(MaxPooling1D(pool_size= pool_size))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(dropout))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    #model.summary()\n",
    "    try:\n",
    "        model = multi_gpu_model(model, gpus = 4)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "    model.compile(loss='binary_crossentropy', optimizer=optim, metrics=['accuracy'])\n",
    "    t0 = time.time()\n",
    "    model.fit(x_train,y_train, batch_size=batch_size, epochs=epochs, verbose=0, class_weight=class_weights, shuffle=True)\n",
    "    scores = model.evaluate(x_test, y_test, verbose=0)\n",
    "    t1 = time.time()\n",
    "    total_run = t1-t0\n",
    "    Times.append(total_run)\n",
    "    print(\"%s: %.5f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "    print(\"%s: %.5f%%\" % (model.metrics_names[0], scores[0]))\n",
    "    print('Fit and Evaluate Time:',total_run)\n",
    "    AccScores.append(scores[1] * 100)\n",
    "    LossScores.append(scores[0])\n",
    "    \n",
    "    #y_pred = model.predict(x_test)\n",
    "    #yy_test = [np.argmax(i) for i in y_test]\n",
    "\n",
    "    #yy_pred = [np.argmax(i) for i in y_pred]\n",
    "  \n",
    "    #new = np.vstack([yy_test,yy_pred])\n",
    "    #print(classification_report(yy_test, yy_pred, digits = 5 ))\n",
    "    #f1 = f1_score(yy_test, y_pred)\n",
    "    #F1Scores.append(f1)\n",
    "    \n",
    "    #ap = average_precision_score(yy_test, y_pred[:,1])\n",
    "    #PrecisionScores.append(ap)\n",
    "    \n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    fpr_keras, tpr_keras, thresholds_keras = roc_curve(yy_test, y_pred[:,0],pos_label=0)\n",
    "    auc_keras = auc(fpr_keras, tpr_keras)\n",
    "    AucScores.append(auc_keras)\n",
    "    \"\"\"\n",
    "    del model\n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    gc.collect()\n",
    "\n",
    "    \n",
    "print(\"%.5f%% (+/- %.5f%%)\" % (np.mean(AccScores), np.std(AccScores)))\n",
    "print(\"%.5f%% (+/- %.5f%%)\" % (np.mean(LossScores), np.std(LossScores)))\n",
    "print(\"%.5f%% (+/- %.5f%%)\" % (np.mean(Times), np.std(Times)))\n",
    "#print(\"%.5f%% (+/- %.5f%%)\" % (np.mean(AucScores), np.std(AucScores)))\n",
    "#print(\"%.5f%% (+/- %.5f%%)\" % (np.mean(F1Scores), np.std(F1Scores)))\n",
    "#print(\"%.5f%% (+/- %.5f%%)\" % (np.mean(PrecisionScores), np.std(PrecisionScores)))\n",
    "t3 = time.time()\n",
    "total_time = t3-t2\n",
    "print('Time to do everything:',total_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[89.105224609375,\n",
       " 89.03645277023315,\n",
       " 89.33526277542114,\n",
       " 88.51708769798279,\n",
       " 89.10285234451294,\n",
       " 88.60245943069458,\n",
       " 89.28071856498718,\n",
       " 88.77084255218506,\n",
       " 89.34000730514526,\n",
       " 88.00957798957825,\n",
       " 89.23091292381287,\n",
       " 89.05542492866516,\n",
       " 88.89890313148499,\n",
       " 88.96530270576477,\n",
       " 88.92261981964111,\n",
       " 88.27519416809082,\n",
       " 89.04356360435486,\n",
       " 89.57952857017517,\n",
       " 89.30443525314331,\n",
       " 89.37557935714722,\n",
       " 89.11945223808289,\n",
       " 88.41748237609863,\n",
       " 89.10759687423706,\n",
       " 89.32103514671326,\n",
       " 89.41826820373535,\n",
       " 89.44435119628906,\n",
       " 88.50522637367249,\n",
       " 89.34474587440491,\n",
       " 88.87755870819092,\n",
       " 89.85462784767151,\n",
       " 89.26411867141724,\n",
       " 89.01036381721497,\n",
       " 88.26807737350464,\n",
       " 88.24673295021057,\n",
       " 88.5431706905365,\n",
       " 88.93921971321106,\n",
       " 88.4388267993927,\n",
       " 88.43645453453064,\n",
       " 89.24751877784729,\n",
       " 89.45621252059937,\n",
       " 88.3866548538208,\n",
       " 88.55740427970886,\n",
       " 88.40088248252869,\n",
       " 89.09336924552917,\n",
       " 88.52419853210449,\n",
       " 89.22617435455322,\n",
       " 88.04515600204468,\n",
       " 88.98427486419678,\n",
       " 88.38902711868286]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AccScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.2543829416274278,\n",
       " 0.25466985323523983,\n",
       " 0.253604208176749,\n",
       " 0.26864633259369236,\n",
       " 0.2626929012333001,\n",
       " 0.2600378316262167,\n",
       " 0.2589729799943957,\n",
       " 0.2546202524696774,\n",
       " 0.25363221411427456,\n",
       " 0.2767420284393336,\n",
       " 0.26955162904495605,\n",
       " 0.25408717550116977,\n",
       " 0.2582767935983965,\n",
       " 0.25737923893893866,\n",
       " 0.26277419243781897,\n",
       " 0.2717614280874529,\n",
       " 0.24872770649891732,\n",
       " 0.25570197520383514,\n",
       " 0.2629513985037402,\n",
       " 0.261552622320169,\n",
       " 0.2573881965072878,\n",
       " 0.26006134653780105,\n",
       " 0.2551828257172892,\n",
       " 0.2559424762593509,\n",
       " 0.2577970111108511,\n",
       " 0.24904361947571224,\n",
       " 0.2651807758127136,\n",
       " 0.25775008423846124,\n",
       " 0.258663061272344,\n",
       " 0.24555993769185788,\n",
       " 0.2507875724507777,\n",
       " 0.2617237547829376,\n",
       " 0.2587253046172668,\n",
       " 0.26951708561742205,\n",
       " 0.2620068006861523,\n",
       " 0.25170213104571504,\n",
       " 0.25689226990108865,\n",
       " 0.26715390335801237,\n",
       " 0.251633169311528,\n",
       " 0.2516113939876236,\n",
       " 0.2678919419576293,\n",
       " 0.25702410885892296,\n",
       " 0.2592890893967447,\n",
       " 0.25922640642127337,\n",
       " 0.26364589213584966,\n",
       " 0.2529005710153328,\n",
       " 0.26422306826310743,\n",
       " 0.25475019325397547,\n",
       " 0.25856195903409324]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LossScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[73.58207058906555,\n",
       " 67.9497230052948,\n",
       " 66.09202003479004,\n",
       " 66.40930938720703,\n",
       " 66.01029968261719,\n",
       " 66.26499557495117,\n",
       " 65.97678899765015,\n",
       " 65.20565915107727,\n",
       " 65.61148595809937,\n",
       " 66.53992629051208,\n",
       " 65.16773509979248,\n",
       " 65.92559599876404,\n",
       " 67.15752220153809,\n",
       " 65.67529726028442,\n",
       " 66.60524153709412,\n",
       " 66.53224110603333,\n",
       " 66.14062714576721,\n",
       " 65.496098279953,\n",
       " 66.73258566856384,\n",
       " 66.54114866256714,\n",
       " 66.388028383255,\n",
       " 65.91399812698364,\n",
       " 66.5015778541565,\n",
       " 65.91160345077515,\n",
       " 65.80597567558289,\n",
       " 66.72379064559937,\n",
       " 65.20480751991272,\n",
       " 66.84970307350159,\n",
       " 65.67833209037781,\n",
       " 66.23423457145691,\n",
       " 65.36672830581665,\n",
       " 65.6241614818573,\n",
       " 66.21689987182617,\n",
       " 66.76148271560669,\n",
       " 65.87491464614868,\n",
       " 66.12395215034485,\n",
       " 65.21816635131836,\n",
       " 66.76885986328125,\n",
       " 65.84142899513245,\n",
       " 66.20994973182678,\n",
       " 65.91570496559143,\n",
       " 65.62564492225647,\n",
       " 65.70773124694824,\n",
       " 66.72771191596985,\n",
       " 65.6626398563385,\n",
       " 65.69525027275085,\n",
       " 65.56711387634277,\n",
       " 66.36722707748413,\n",
       " 65.67475295066833]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
